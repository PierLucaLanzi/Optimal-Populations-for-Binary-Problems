{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e02e86a-78b2-47c3-a696-537a1f1aafea",
   "metadata": {},
   "source": [
    "# Compute Optimal Generalization for Multistep Problems\n",
    "All the shared functions are in the xcslib python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f06aaeda-d1ce-40d7-9bba-affdf1fd7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# we apply AgglomerativeClustering with a limit of 2*EpsilonError \n",
    "# so that it does not merge whose distance is above that value \n",
    "# DBSCAN might also be used setting adequate density parameters\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91495d97-0862-4103-807f-7e7610785aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xcslib2 import load_xcslib_population\n",
    "from xcslib2 import compute_cluster_prediction_statistics\n",
    "from xcslib2 import generate_espresso_for_action,generate_complete_representation,load_pla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9cb2f-a114-4ea7-b10e-2467bed15b62",
   "metadata": {},
   "source": [
    "## Overwrites some of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feede3af-797e-4aa7-acf3-a4c4d0785e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_expected_payoff(population, error_threshold=10, min_sample=5, no_clusters=None, use_numerosity=True, use_dbscan=False, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        print(\"POPULATION SIZE = %d\"%len(population))\n",
    "    \n",
    "    if use_dbscan:\n",
    "        if verbose:\n",
    "            print(\"WARNING: using DBSCAN (old version).\")\n",
    "        clustering = DBSCAN(eps=error_threshold, min_samples=min_sample)\n",
    "    else:\n",
    "        clustering = AgglomerativeClustering(n_clusters=no_clusters,distance_threshold=2*error_threshold)\n",
    "        \n",
    "    predictions = generate_prediction_vector(population, use_numerosity=use_numerosity)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"POPULATION SIZE = %d PREDICTIONS TO CLUSTER = %d\"%(len(population),len(predictions)))\n",
    "    \n",
    "    clustering.fit(predictions)\n",
    "          \n",
    "    population['label'] = clustering.labels_\n",
    "\n",
    "    if verbose:\n",
    "        print(\"# LABELS = %d # LABEL VALUES = %d\"%(len(clustering.labels_),len(population['label'].unique())))\n",
    "        print(population[['label','prediction']].groupby(by=['label']).mean())\n",
    "        print(population[['label','prediction']].groupby(by=['label']).std())\n",
    "\n",
    "    return population\n",
    "\n",
    "def generate_prediction_vector(population, use_numerosity=True):\n",
    "    \n",
    "    if (not use_numerosity):\n",
    "        return population.values.reshape(-1,1)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i,row in population.iterrows():\n",
    "        predictions += [row['prediction']]*row['numerosity']\n",
    "\n",
    "    return np.array(predictions).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48bc8235-2077-43b8-bbbe-f58de1003e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optimized_population(problem, error_threshold, source_directory, destination_directory, espresso_command, experiment=0, create_complete_representation=True,run_minimization=True, verbose=False, no_clusters=None):\n",
    "    \"\"\"run_minimization: if true it also calls the espresso functions.\"\"\"\n",
    "    \n",
    "    # create the destination directory\n",
    "    pathlib.Path(destination_directory).mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "    # XCS configuration file\n",
    "    config_path = source_directory + \"/confsys.%s\"%(problem)\n",
    "    \n",
    "    # population file\n",
    "    population_path = \"%s/population.%s-%04d.gz\"%(source_directory,problem,experiment)\n",
    "\n",
    "    # path to pla files\n",
    "    pla_path = \"%s/%s.pla\"%(destination_directory,problem)\n",
    "\n",
    "    prediction_statistics_path = \"%s/%s_ps.csv\"%(destination_directory,problem)    \n",
    "    \n",
    "    ################################################################################\n",
    "    # Step 1. Load the population\n",
    "    #         Cluster the payoff values\n",
    "    #         Compute the statistics of the clusters\n",
    "    ################################################################################\n",
    "    \n",
    "    if (verbose):\n",
    "        print(\"Step 1. Load the population\")\n",
    "        print(\"        Cluster the payoff values\")\n",
    "        print(\"        Compute the statistics of the clusters\")\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "    # load population\n",
    "    df_population = load_xcslib_population(population_path)\n",
    "\n",
    "    # save the population as csv\n",
    "    df_population.to_csv(population_path.replace(\".gz\",\".csv.gz\"),index=False,compression=\"gzip\")\n",
    "\n",
    "    # cluster the payoff values\n",
    "    df_cluster = cluster_expected_payoff(df_population, error_threshold=error_threshold, min_sample=1, no_clusters=no_clusters)\n",
    "\n",
    "    # compute the stastistics for every values\n",
    "    prediction_statistics, df_prediction_statistics = compute_cluster_prediction_statistics(df_cluster)\n",
    "    df_prediction_statistics.to_csv(prediction_statistics_path,index=False)\n",
    "\n",
    "    # payoff dictionary\n",
    "    payoff_values_table = df_cluster[['label','prediction']].groupby(by=['label']).mean()    \n",
    "    payoff_values_table.reset_index(inplace=True)\n",
    "\n",
    "    payoff_values = {}\n",
    "    for i,row in payoff_values_table.iterrows():\n",
    "        payoff_values[row['label']]=row['prediction']\n",
    "    \n",
    "    # compute population size\n",
    "    with open(config_path,\"r\") as CONFIG:\n",
    "        str_config = CONFIG.read()\n",
    "    population_size = int([s.strip() for s in str_config.split(\"\\n\") if (s.strip()!=\"\" and s.strip()[:17]=='population size =')][0].split(\" = \")[1])        \n",
    "    no_action_bits = int([s.strip() for s in str_config.split(\"\\n\") if (s.strip()!=\"\" and  s.strip()[:17]=='number of bits = ')][0].split(\" = \")[1])    \n",
    "\n",
    "    ################################################################################\n",
    "    # Step 2. Create the pla file for each action\n",
    "    ################################################################################\n",
    "\n",
    "    if (verbose):\n",
    "        print(\"Step 2. Create the pla file for each action\")\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    actions = df_population['action'].unique()\n",
    "    actions.sort()\n",
    "    \n",
    "    espresso_files = {}\n",
    "    for action in actions:\n",
    "        espresso_action = generate_espresso_for_action(df_cluster,action)\n",
    "        espresso_files[str(action)] = espresso_action\n",
    "\n",
    "    action_pla_paths = {}\n",
    "\n",
    "    for action in espresso_files.keys():    \n",
    "\n",
    "        action_pla_path = pla_path.replace(\".pla\",\"_a\"+action+\".pla\")\n",
    "\n",
    "        action_pla_paths[action] = action_pla_path\n",
    "\n",
    "        with open(action_pla_path, \"w\") as OUTPUT:\n",
    "            OUTPUT.write(espresso_files[action])\n",
    "            \n",
    "    ################################################################################\n",
    "    # Step 3. Generate complete representation for every action\n",
    "    ################################################################################\n",
    "\n",
    "    # generate the filenames for the complete and minimized representations so to \n",
    "    # check whether it is necessary to create them or they are already available \n",
    "    # so we skip the step\n",
    "\n",
    "    complete_action_pla_paths = {}\n",
    "    minimized_pla_paths = {}\n",
    "\n",
    "    for action in action_pla_paths.keys():\n",
    "        action_pla_path = action_pla_paths[action]\n",
    "        complete_action_pla_paths[action] = action_pla_path.replace(\".pla\",\"_complete.pla\")    \n",
    "        minimized_pla_paths[action] = complete_action_pla_paths[action].replace(\".pla\",\"_minimized.pla\")\n",
    "\n",
    "    # if the creation of the complete representation is needed\n",
    "    if (create_complete_representation):\n",
    "\n",
    "        if (verbose):\n",
    "            print(\"Step 3. Generate complete representation for every action\")\n",
    "            print(\"\\n\\n\")\n",
    "        \n",
    "        # complete_action_pla_paths = {}\n",
    "        for action in action_pla_paths.keys():\n",
    "            if (verbose):\n",
    "                print(\"        Action \",str(action))\n",
    "            \n",
    "            generate_complete_representation(action_pla_paths[action],complete_action_pla_paths[action])\n",
    "                    \n",
    "    ################################################################################\n",
    "    # Step 4. Optimize the PLA representation for each action\n",
    "    ################################################################################\n",
    "\n",
    "    if (not run_minimization):\n",
    "        print(\"The parameter run_minimization is set to False\\nthus the process stops at generation\")\n",
    "        return\n",
    "        \n",
    "    if (verbose):\n",
    "        print(\"Step 4. Optimize the PLA representation for each action\")\n",
    "        print(\"\\n\\n\")\n",
    "    \n",
    "    # minimized_pla_paths = {}\n",
    "    for action in complete_action_pla_paths.keys():\n",
    "\n",
    "        # action_pla_path = complete_action_pla_paths[action]\n",
    "\n",
    "        # minimized_pla_path = action_pla_path.replace(\".pla\",\"_minimized.pla\")\n",
    "\n",
    "        # minimized_pla_paths[action] = minimized_pla_path\n",
    "\n",
    "        if (not Path(minimized_pla_paths[action]).is_file()):\n",
    "            print(\"PATH => \",minimized_pla_paths[action])\n",
    "            minimization_command = \"%s %s > %s\"%(espresso_command,complete_action_pla_paths[action], minimized_pla_paths[action])\n",
    "\n",
    "            minimization_result = os.system(minimization_command)\n",
    "            if (minimization_result!=0):\n",
    "                print(\"MINIMIZATION FAILED FOR ACTION \"+action)\n",
    "                print(minimization_command)      \n",
    "        else:\n",
    "            if (verbose):\n",
    "                print(\"       ==> skipping minimization since the minimized file already exists.\")\n",
    "                print(\"           %s\"%(minimized_pla_paths[action].split(os.sep)[-1]))\n",
    "\n",
    "    ################################################################################\n",
    "    # Step 5. Generate the population by joining all the minimized solutions\n",
    "    ################################################################################\n",
    "\n",
    "    if (verbose):\n",
    "        print(\"Step 5. Generate the population by joining all the minimized solutions\")\n",
    "        print(\"\\n\\n\")\n",
    "            \n",
    "    pla = {}\n",
    "    for action in minimized_pla_paths.keys():\n",
    "        print(\"==>\",minimized_pla_paths[action])\n",
    "        pla[action] = load_pla(minimized_pla_paths[action])\n",
    "        \n",
    "    population = {\n",
    "        'id':[],\n",
    "        'condition':[],\n",
    "        'action':[],\n",
    "        'prediction':[],\n",
    "        'error':[],\n",
    "        'fitness':[],\n",
    "        'action_set_size':[],\n",
    "        'experience':[],\n",
    "        'numerosity':[],\n",
    "    }\n",
    "\n",
    "    current_id = 0\n",
    "\n",
    "    for action in pla.keys():\n",
    "        input_output, no_input_bits, no_output_bits, input_labels, output_labels = pla[action]\n",
    "\n",
    "        for input_string in input_output.keys():\n",
    "            output_string = input_output[input_string]\n",
    "\n",
    "            condition = input_string.replace(\"-\",\"#\")        \n",
    "            prediction = payoff_values[output_string.index('1')]       \n",
    "\n",
    "            population['id'].append(current_id)\n",
    "            population['condition'].append(condition)\n",
    "            population['action'].append(action)\n",
    "            population['prediction'].append(prediction)\n",
    "            population['error'].append(0.0)\n",
    "            population['fitness'].append(1.0)\n",
    "            population['action_set_size'].append(100)\n",
    "            population['experience'].append(100)\n",
    "            population['numerosity'].append(0)\n",
    "\n",
    "            current_id = current_id + 1\n",
    "\n",
    "    df = pd.DataFrame.from_dict(population)\n",
    "    \n",
    "    numerosity = int(float(population_size)/len(df))\n",
    "    numerosity_values = [numerosity]*(len(df)-1)\n",
    "    numerosity_values.append(population_size-sum(numerosity_values))\n",
    "    df['numerosity'] = numerosity_values    \n",
    "    \n",
    "    minimized_population_path = source_directory+\"/population.%s-%04d.gz\"%(problem+\"_min\",experiment)\n",
    "\n",
    "    df.to_csv(minimized_population_path,sep=\"\\t\", compression=\"gzip\",index=False,header=False)\n",
    "    \n",
    "    df[['condition','action','prediction']].to_csv(source_directory+\"/optimal_population.%s-%04d\"%(problem,experiment),sep=\"\\t\", index=False,header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b30429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population_from_pla_files(minimized_pla_paths, population_size, problem, payoff_values, destination_directory):\n",
    "\n",
    "    original_pla = {}    \n",
    "    pla = {}\n",
    "    for minimized_pla_path in minimized_pla_paths:\n",
    "        action = minimized_pla_path.split(os.sep)[-1].split(\"_\")[1][1:]\n",
    "        pla[action] = load_pla(minimized_pla_path)\n",
    "        \n",
    "    population = {\n",
    "        'id':[],\n",
    "        'condition':[],\n",
    "        'action':[],\n",
    "        'prediction':[],\n",
    "        'error':[],\n",
    "        'fitness':[],\n",
    "        'action_set_size':[],\n",
    "        'experience':[],\n",
    "        'numerosity':[],\n",
    "    }\n",
    "\n",
    "    current_id = 0\n",
    "\n",
    "    for action in pla.keys():\n",
    "        input_output, no_input_bits, no_output_bits, input_labels, output_labels = pla[action]\n",
    "\n",
    "        # print(\"OUTPUT LABELS \",output_labels)\n",
    "        \n",
    "        output_labels_list = [int(label[1:]) for label in output_labels[4:].strip().split(\" \")]\n",
    "        # print(output_labels_list)\n",
    "\n",
    "        for input_string in input_output.keys():\n",
    "            output_string = input_output[input_string]\n",
    "\n",
    "            condition = input_string.replace(\"-\",\"#\")        \n",
    "            prediction = payoff_values[output_string.index('1')]       \n",
    "\n",
    "            population['id'].append(current_id)\n",
    "            population['condition'].append(condition)\n",
    "            population['action'].append(action)\n",
    "            population['prediction'].append(prediction)\n",
    "            population['error'].append(0.0)\n",
    "            population['fitness'].append(1.0)\n",
    "            population['action_set_size'].append(100)\n",
    "            population['experience'].append(100)\n",
    "            population['numerosity'].append(0)\n",
    "\n",
    "            current_id = current_id + 1\n",
    "\n",
    "    df = pd.DataFrame.from_dict(population)\n",
    "    \n",
    "    numerosity = int(float(population_size)/len(df))\n",
    "    numerosity_values = [numerosity]*(len(df)-1)\n",
    "    numerosity_values.append(population_size-sum(numerosity_values))\n",
    "    df['numerosity'] = numerosity_values    \n",
    "    \n",
    "    experiment = 0\n",
    "    minimized_population_path = destination_directory+\"/population.%s-%04d.gz\"%(problem+\"_min\",experiment)\n",
    "\n",
    "    df.to_csv(minimized_population_path,sep=\"\\t\", compression=\"gzip\",index=False,header=False)\n",
    "    \n",
    "    df[['condition','action','prediction']].to_csv(destination_directory+\"/optimal_population.%s-%04d\"%(problem,experiment),sep=\"\\t\", index=False,header=False)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784c214",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c33c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# espresso_command = \"../../../espresso-logic-master/bin/espresso -Dexact\"\n",
    "espresso_command = \"../espresso-logic-master/bin/espresso \"\n",
    "experiments_directory = \"../experiments-qlearning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a6758-e0f5-48f2-8950-f22664db546a",
   "metadata": {},
   "source": [
    "## Experimenti for Woods1q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93f714-5c6d-4eed-8c29-09f67dcd8d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1. Load the population\n",
      "        Cluster the payoff values\n",
      "        Compute the statistics of the clusters\n",
      "\n",
      "\n",
      "\n",
      "Step 2. Create the pla file for each action\n",
      "\n",
      "\n",
      "\n",
      "Step 3. Generate complete representation for every action\n",
      "\n",
      "\n",
      "\n",
      "        Action  000\n",
      "        Action  001\n",
      "        Action  010\n",
      "        Action  011\n",
      "        Action  100\n",
      "        Action  101\n",
      "        Action  110\n",
      "        Action  111\n",
      "Step 4. Optimize the PLA representation for each action\n",
      "\n",
      "\n",
      "\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a000_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a001_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a010_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a011_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a100_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a101_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a110_complete_minimized.pla\n",
      "       ==> skipping minimization since the minimized file already exists.\n",
      "           woods1q_a111_complete_minimized.pla\n",
      "Step 5. Generate the population by joining all the minimized solutions\n",
      "\n",
      "\n",
      "\n",
      "PATHS {'000': '../experiments-qlearning//woods1/pla//woods1q_a000_complete_minimized.pla', '001': '../experiments-qlearning//woods1/pla//woods1q_a001_complete_minimized.pla', '010': '../experiments-qlearning//woods1/pla//woods1q_a010_complete_minimized.pla', '011': '../experiments-qlearning//woods1/pla//woods1q_a011_complete_minimized.pla', '100': '../experiments-qlearning//woods1/pla//woods1q_a100_complete_minimized.pla', '101': '../experiments-qlearning//woods1/pla//woods1q_a101_complete_minimized.pla', '110': '../experiments-qlearning//woods1/pla//woods1q_a110_complete_minimized.pla', '111': '../experiments-qlearning//woods1/pla//woods1q_a111_complete_minimized.pla'}\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a000_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a001_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a010_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a011_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a100_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a101_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a110_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods1/pla//woods1q_a111_complete_minimized.pla\n",
      "    id         condition action  prediction  error  fitness  action_set_size  \\\n",
      "0    0  ############1###    000       700.0    0.0      1.0              100   \n",
      "1    1  ############0###    000       490.0    0.0      1.0              100   \n",
      "2    2  ################    001       490.0    0.0      1.0              100   \n",
      "3    3  ########1#######    010       700.0    0.0      1.0              100   \n",
      "4    4  ########0#######    010       490.0    0.0      1.0              100   \n",
      "5    5  #########1######    011       700.0    0.0      1.0              100   \n",
      "6    6  #######1########    011      1000.0    0.0      1.0              100   \n",
      "7    7  0######0#0######    011       490.0    0.0      1.0              100   \n",
      "8    8  1###############    011       700.0    0.0      1.0              100   \n",
      "9    9  #########1######    100      1000.0    0.0      1.0              100   \n",
      "10  10  ############1#1#    100       490.0    0.0      1.0              100   \n",
      "11  11  ############0#1#    100       700.0    0.0      1.0              100   \n",
      "12  12  ##########0###0#    100       490.0    0.0      1.0              100   \n",
      "13  13  #########01####0    100       700.0    0.0      1.0              100   \n",
      "14  14  ###########1####    101      1000.0    0.0      1.0              100   \n",
      "15  15  ########1#0#####    101       490.0    0.0      1.0              100   \n",
      "16  16  ##########0#1###    101       490.0    0.0      1.0              100   \n",
      "17  17  ##1#1###########    101       490.0    0.0      1.0              100   \n",
      "18  18  1#1#############    101       490.0    0.0      1.0              100   \n",
      "19  19  0###0###0##0##0#    101       700.0    0.0      1.0              100   \n",
      "20  20  ##0#####0##00###    101       700.0    0.0      1.0              100   \n",
      "21  21  ##########10####    101       700.0    0.0      1.0              100   \n",
      "22  22  #############1##    110      1000.0    0.0      1.0              100   \n",
      "23  23  ########10######    110       490.0    0.0      1.0              100   \n",
      "24  24  ######1#0#######    110       700.0    0.0      1.0              100   \n",
      "25  25  ######0###0#####    110       490.0    0.0      1.0              100   \n",
      "26  26  #######0##1##0##    110       700.0    0.0      1.0              100   \n",
      "27  27  #############1##    111       700.0    0.0      1.0              100   \n",
      "28  28  ###############1    111      1000.0    0.0      1.0              100   \n",
      "29  29  ####0########0#0    111       490.0    0.0      1.0              100   \n",
      "30  30  ####1###########    111       700.0    0.0      1.0              100   \n",
      "\n",
      "    experience  numerosity  \n",
      "0          100           0  \n",
      "1          100           0  \n",
      "2          100           0  \n",
      "3          100           0  \n",
      "4          100           0  \n",
      "5          100           0  \n",
      "6          100           0  \n",
      "7          100           0  \n",
      "8          100           0  \n",
      "9          100           0  \n",
      "10         100           0  \n",
      "11         100           0  \n",
      "12         100           0  \n",
      "13         100           0  \n",
      "14         100           0  \n",
      "15         100           0  \n",
      "16         100           0  \n",
      "17         100           0  \n",
      "18         100           0  \n",
      "19         100           0  \n",
      "20         100           0  \n",
      "21         100           0  \n",
      "22         100           0  \n",
      "23         100           0  \n",
      "24         100           0  \n",
      "25         100           0  \n",
      "26         100           0  \n",
      "27         100           0  \n",
      "28         100           0  \n",
      "29         100           0  \n",
      "30         100           0  \n"
     ]
    }
   ],
   "source": [
    "# directory where the files are saved\n",
    "problem_directory = \"woods1\"\n",
    "\n",
    "# extension used to save the q-table\n",
    "problem_extension = \"woods1q\"\n",
    "\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "\n",
    "# error threshold for XCS definition of accurate classifiers\n",
    "error_threshold = 10\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3481f5-113d-4d37-b08a-89dbfbaac04f",
   "metadata": {},
   "source": [
    "## Experimenti for Maze4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27aad71-1ee6-47a6-92d5-a8673c63906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_directory = \"maze4\"\n",
    "problem_extension = \"maze4q\"\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "error_threshold = 10\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc80cb7-f006-4ff2-918c-92596829b147",
   "metadata": {},
   "source": [
    "## Experimenti for Maze5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f066a-c78c-422b-a2b4-5e67920ba5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_directory = \"maze5\"\n",
    "problem_extension = \"maze5q\"\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "error_threshold = 10\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc182e01-98fe-481f-b201-2d58c2001567",
   "metadata": {},
   "source": [
    "## Experimenti for Maze6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b20c55-14cb-4812-b7f4-cb82f279c3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.02 s, sys: 61.8 ms, total: 7.08 s\n",
      "Wall time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problem_directory = \"maze6\"\n",
    "problem_extension = \"maze6q\"\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "error_threshold = 10\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d526a7d",
   "metadata": {},
   "source": [
    "## Experiments for Woods14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1f2f7-6a37-407d-9f27-97d1f4050b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.72 s, sys: 45.8 ms, total: 3.76 s\n",
      "Wall time: 3.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problem_directory = \"woods14\"\n",
    "problem_extension = \"woods14q\"\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "error_threshold = 0.1\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5863dd-229a-411b-8015-2a6ca19d5cce",
   "metadata": {},
   "source": [
    "## Experimenti for Woods2\n",
    "The full run takes around 35 minutes - 1.47 minutes of actual time. The bottleneck is the creation of the complete representations. In this case, we turned it off since the minimized pla files are already available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fd37412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> ../experiments-qlearning//woods2/pla//woods2q_a000_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a001_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a010_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a011_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a100_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a101_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a110_complete_minimized.pla\n",
      "==> ../experiments-qlearning//woods2/pla//woods2q_a111_complete_minimized.pla\n",
      "    id                 condition action  prediction  error  fitness  \\\n",
      "0    0  ###################1####    000       700.0    0.0      1.0   \n",
      "1    1  ###################0####    000       490.0    0.0      1.0   \n",
      "2    2  ########################    001       490.0    0.0      1.0   \n",
      "3    3  #############1##########    010       700.0    0.0      1.0   \n",
      "4    4  #############0##########    010       490.0    0.0      1.0   \n",
      "5    5  ############1###########    011       700.0    0.0      1.0   \n",
      "6    6  #########1##############    011      1000.0    0.0      1.0   \n",
      "7    7  #0#######0##0###########    011       490.0    0.0      1.0   \n",
      "8    8  #1######################    011       700.0    0.0      1.0   \n",
      "9    9  ############1###########    100      1000.0    0.0      1.0   \n",
      "10  10  ###################1##1#    100       490.0    0.0      1.0   \n",
      "11  11  ###################0##1#    100       700.0    0.0      1.0   \n",
      "12  12  ################0#####0#    100       490.0    0.0      1.0   \n",
      "13  13  ############0###1#####0#    100       700.0    0.0      1.0   \n",
      "14  14  ###############1########    101      1000.0    0.0      1.0   \n",
      "15  15  #############1##0#######    101       490.0    0.0      1.0   \n",
      "16  16  ################0##1####    101       490.0    0.0      1.0   \n",
      "17  17  #0#####0#####0##0#####0#    101       700.0    0.0      1.0   \n",
      "18  18  ####1##1################    101       490.0    0.0      1.0   \n",
      "19  19  #1##1###################    101       490.0    0.0      1.0   \n",
      "20  20  ####0########0##0##0####    101       700.0    0.0      1.0   \n",
      "21  21  ###############01#######    101       700.0    0.0      1.0   \n",
      "22  22  ##################1#####    110      1000.0    0.0      1.0   \n",
      "23  23  ############01##########    110       490.0    0.0      1.0   \n",
      "24  24  ##########1##0##########    110       700.0    0.0      1.0   \n",
      "25  25  ##########0#####0#######    110       490.0    0.0      1.0   \n",
      "26  26  ##########0#####1#0#####    110       700.0    0.0      1.0   \n",
      "27  27  ##################1#####    111       700.0    0.0      1.0   \n",
      "28  28  #####################1##    111      1000.0    0.0      1.0   \n",
      "29  29  #######0##########0##0##    111       490.0    0.0      1.0   \n",
      "30  30  #######1################    111       700.0    0.0      1.0   \n",
      "\n",
      "    action_set_size  experience  numerosity  \n",
      "0               100         100           0  \n",
      "1               100         100           0  \n",
      "2               100         100           0  \n",
      "3               100         100           0  \n",
      "4               100         100           0  \n",
      "5               100         100           0  \n",
      "6               100         100           0  \n",
      "7               100         100           0  \n",
      "8               100         100           0  \n",
      "9               100         100           0  \n",
      "10              100         100           0  \n",
      "11              100         100           0  \n",
      "12              100         100           0  \n",
      "13              100         100           0  \n",
      "14              100         100           0  \n",
      "15              100         100           0  \n",
      "16              100         100           0  \n",
      "17              100         100           0  \n",
      "18              100         100           0  \n",
      "19              100         100           0  \n",
      "20              100         100           0  \n",
      "21              100         100           0  \n",
      "22              100         100           0  \n",
      "23              100         100           0  \n",
      "24              100         100           0  \n",
      "25              100         100           0  \n",
      "26              100         100           0  \n",
      "27              100         100           0  \n",
      "28              100         100           0  \n",
      "29              100         100           0  \n",
      "30              100         100           0  \n",
      "CPU times: user 253 ms, sys: 6.53 ms, total: 259 ms\n",
      "Wall time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "problem_directory = \"woods2\"\n",
    "problem_extension = \"woods2q\"\n",
    "source_directory = \"%s/%s/\"%(experiments_directory,problem_directory)\n",
    "destination_directory = \"%s/%s/pla/\"%(experiments_directory,problem_directory)\n",
    "error_threshold = 10\n",
    "generate_optimized_population(problem_extension, error_threshold, source_directory, destination_directory, espresso_command, \\\n",
    "    create_complete_representation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f71a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
